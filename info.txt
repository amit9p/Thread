loan_data.csv

This CSV (comma separated values) file has the following loan related data (fields):

loan_data.csv “input_path” variable in config.yaml will indicate the HDFS location of these files. “config.yaml” file will be supplied by the Auto SkillGrader platform and it will be copied at the project root folder at run time.

Loan ID – unique loan id ·

Customer ID – customer id ·

Loan Status – status of the loan: fully paid / charged off · 

Current Loan Amount – loan amount · 

Term – loan term (short or long) · 

Credit Score – credit score for the customer · 

Annual Income – annual income of the customer · Years in current job – number of years in current job · Home Ownership – Customer’s home ownership: owned house, rented house, etc. ·

Purpose – purpose of this loan · 

Monthly Debt – Monthly debt for the customer · 

Years of Credit History – how many year credit history available · 

Months since last delinquent · 

Number of Open Accounts · 

Number of Credit Problems · 

Current Credit Balance · 

Maximum Open Credit ·

Bankruptcies · 

Tax Liens – number of liens on the property.



Output files expected:

credit_score_impact.csv

credit_age_impact.csv

annual_income_impact.csv

emp_history_impact.csv

home_ownership_impact.csv

“output_path” variable in config.yaml will point to file location path in HDFS to where these files need to be created.

Credit Score Impact:

· From the Loan Data file, impact of Credit Score on the loan status need to be identified and written into credit_score_impact.csv file.

· The output file, credit_score_impact.csv, should be a CSV (comma separated values) file with the following format:

credit_score_category - Should have one of the following values: · Poor · Average · Good · Very Good · Exceptional Please refer below on how to derive Credit Score Category from the “Credit Score” input field.

fully_paid_count - Number of loan records matching loan status as “Fully Paid” for a given Credit Score Category

charged_off_count - Number of loan records matching loan status as “Charged Off” for a given Credit Score Category.

Credit Score data in the input file needs to be cleaned up before doing this impact analysis. Data cleansing logic is given below:

o The Credit Score value should be in the range of 300 to 850.

o For some records, this value for this field in the input file may be in the scale of 10. (for e.g. 7290 instead of 729; 7120 instead of 712, etc.). If the Credit Score value is in 4 digit, it should be divided by 10.

o For some records, Credit Score value may be empty. Use the following logic to arrive Credit Score value:

§ Calculate mean value of the Credit Score for each type of “Term” (Short Term and Long Term). You would have two mean value, one mean Credit Score for “Short Term” and another mean Credit Score for “Long Term”

§ Fill in the empty Credit Score using the above calculated mean Credit Score value based on the value of the Term for the given record. (for e.g. if the Credit Score value is empty for the given loan record with the “Term” as Short Term, then assign the calculated mean Credit Score value for Short Term to this field)

o Categorize Credit Score using Experian’s Credit Score Range:

§ Poor, if Credit Score is < 580

§ Average, if Credit Score is >= 580 and < 670

§ Good, if Credit Score is >= 670 and < 740

§ Very Good, if Credit Score is >= 740 and < 800

§ Exceptional, if Credit Score is >= 800 and <= 850

· For each Credit Score Category, calculate the count for “Fully Paid” and “Charged Off” Loan Status records :

· If there are no records for a given Credit Score Category (e.g. Exceptional), do not show it in the output file

· Sample credit_score_impact.csv output file:

credit_score_category,fully_paid_count,charged_off_count

Poor,100,5000

Average,500,3000

Good,1000,2000

Very Good,2000,500

Exceptional,0,0

Credit Age Impact:

· From the Loan Data file, impact of Credit Age and Credit Score on the loan status need to be identified and written into credit_age_impact.csv file.

· The output file, credit_age_impact.csv, should be a CSV (comma separated values) file with the following format:

credit_age- Should have one of the following values: · Short · Good · Exceptional Please refer below on how to derive Credit Age from the “Years of Credit History” input field.

credit_score_category - Should have one of the following values: · Poor · Average · Good · Very Good · Exceptional.Please refer Credit Score Impact section how to derive Credit Score Category from the “Credit Score” input field.

fully_paid_count- Number of loan records matching loan status as “Fully Paid” for a given Credit Score Category and Credit Age.

charged_off_count - Number of loan records matching loan status as “Charged Off” for a given Credit Score Category and Credit Age.

· The logic for deriving Credit Age from “Years of Credit History” input field is given below:

o Short, if “Years of Credit History” is < 5

o Good, if “Years of Credit History” is >= 5 and < 20

o Exceptional, if “Years of Credit History” >= 20

· For each combination of Credit Score Category and Credit Age, calculate the count for “Fully Paid” and “Charged Off” Loan Status records :

o If there are no records for a given combination (e.g. “Exceptional” Credit Score Category), do not show them in the output file

· Sample credit_age_impact.csv file:

credit_age,credit_score_category,fully_paid_count,charged_off_count

Short,Poor,100,5000

Short,Average,500,3000

Short,Good,1000,2000

Short,Very Good,2000,500

Good,Poor,100,5000

Good,Average,500,3000

Good,Good,1000,2000

Good,Very Good,2000,500

Exceptional,Poor,100,5000

Exceptional,Average,500,3000

Exceptional,Good,1000,2000

Exceptional,Very Good,2000,500

Annual Income Impact:

· From the Loan Data file, impact of Annual Income on the loan status need to be identified and written into annual_income_impact.csv file.

· The output file, annual_income_impact.csv, should be a CSV (comma separated values) file with the following format:

income_category - Should have one of the following values: · <250K · <500K · <750K · <1M · <2M · <3M · 3M+

Please refer below on how to derive Income Category from the “Annual Income” input field.

fully_paid_% - Percentage of loan records matching loan status as “Fully Paid” for a given Income Category

charged_off_% - Percentage of loan records matching loan status as “Charged Off” for a given Income Category

The logic for deriving Income Category from “Annual Income” input field is given below:

o <250K, if “Annual Income” is < 250,000

o <500K, if “Annual Income” is >= 250,000 and < 500,000

o <750K, if “Annual Income” is >= 500,000 and < 750,000

o <1M, if “Annual Income” is >= 750,000 and < 1,000,000

o <2M, if “Annual Income” is >= 1,000,000 and < 2,000,000

o <3M, if “Annual Income” is >= 2,000,000 and < 3,000,000

o 3M+, if “Annual Income” is >= 3,000,000

o If “Annual Income” field is empty, ignore those records for this impact analysis

· For each Income Category, calculate % of “Fully Paid” and “Charged Off” Loan Status records : e.g. if there 750 records with “Fully Paid” loan status and 250 records with “Charged Off” loan status for the <250K Income Category, then fully_paid_% value will be 75 and charged_off_% value will be 25. Round up the value with no decimal places (if percent calculated is 74.51, then round up to 75, if the percent value is 74.4, then the value will be just 74)

· Sample annual_income_impact.csv file:

income_category,fully_paid_%,charged_off_%

<250K,75,25

<500K,73,27

<750K,74,26

<1M,74,26

<2M,80,20

<3M,84,16

3M+,85,15

Employment History Impact:

· From the Loan Data file, impact of Employment History and Annual Income on the loan status need to be identified and written into emp_history_impact.csv file.

· The output file, emp_history_impact.csv, should be a CSV (comma separated values) file with the following format:

emp_Status - Should have one of the following values: · Junior · Middle · Senior Please refer below on how to derive Emp Status from the “Years in current job” input field.

income_category - Should have one of the following values: · <250K · <500K · <750K · <1M · <2M · <3M · 3M+ Please refer Annual Income Impact section on how to derive Income Category from the “Annual Income” input field.

fully_paid_% - Percentage of loan records matching loan status as “Fully Paid” for a given Emp Status and Income Category

charged_off_% - Percentage of loan records matching loan status as “Charged Off” for a given Emp Status and Income Category.

· The logic for deriving Emp Status from “Years in current job” input field is given below:

o Junior, if “Years in current job” is < 4 years

o Middle, if “Years in current job” is >= 4 years and < 8 years

o Senior, if “Years in current job” is > 8 years

o If “Years in current job” field is empty or n/a, then ignore those records for this impact analysis

· Refer Annual Impact section to derive Income Category field. Ignore the records that have “Annual Income” value as empty.

· For each combination of Emp Status and Income Category, calculate % of “Fully Paid” and “Charged Off” Loan Status records : e.g. if there 750 records with “Fully Paid” loan status and 250 records with “Charged Off” loan status for the Junior Emp Status and <250K Income Category, then fully_paid_% value will be 75 and charged_off_% value will be 25. Round up the value with no decimal places (if percent calculated is 74.51, then round up to 75, if the percent value is 74.4, then the value will be just 74)

· Sample emp_history_impact.csv file:

emp_status,income_category,fully_paid_%,charged_off_%

Junior,<250K,75,25

Junior,<500K,76,24

Junior,<750K,74,26

Junior,<1M,74,26

Junior,<2M,80,20

Junior,<3M,84,16

Junior,3M+,85,15

Middle,<250K,75,25

Middle,<500K,73,27

Middle,<750K,74,26

Middle,<1M,74,26

Middle,<2M,80,20

Middle,<3M,84,16

Middle,3M+,85,15

Senior,<250K,75,25

Senior,<500K,73,27

Senior,<750K,74,26

Senior,<1M,74,26

Senior,<2M,80,20

Senior,<3M,84,16

Senior,3M+,85,15

Home Ownership Impact:

· From the Loan Data file, impact of Home Ownership and Term on the loan status need to be identified and written into home_ownership_impact.csv file.

· The output file, home_ownership_impact.csv, should be a CSV (comma separated values) file with the following format:

home_ownership - Should have one of the following values: · HaveMortgage · Home Mortgage · Own Home · Rent Use “Home Ownership” input field

term - Should have one of the following values: · Short Term · Long Term Use “Term” input field

fully_paid_% - Percentage of loan records matching loan status as “Fully Paid” for a given Home Ownership and Term

charged_off_% - Percentage of loan records matching loan status as “Charged Off” for a given Home Ownership and Term

For each combination of Home Ownership and Term, calculate % of “Fully Paid” and “Charged Off” Loan Status records : e.g. if there 750 records with “Fully Paid” loan status and 250 records with “Charged Off” loan status for “Rent” Home Ownership and “Short Term” , then fully_paid_% value will be 75 and charged_off_% value will be 25. Round up the value with no decimal places (if percent calculated is 74.51, then round up to 75, if the percent value is 74.4, then the value will be just 74)

· Sample home_ownership_impact.csv file:

home_ownership,term,fully_paid_%,charged_off_%

HaveMortgage,Short Term,75,25

HaveMortgage,Long Term,75,25

Home Mortgage,Short Term,75,25

Home Mortgage,Long Term,75,25

Own Home,Short Term,75,25

Own Home,Long Term,75,25

Rent,Short Term,75,25

Rent,Long Term,75,25

##################################

3. Design Considerations / Assumptions:

· Apache Airflow usage is mandatory and this needs to be used for orchestrating various data cleaning/enriching tasks. Please refer https://airflow.apache.org/ if you are not familiar with this tool.

· User should use the “dag_id” provided in “config.yaml” file (which will be copied by Auto SkillGrader platform at run time) . User should not use their own DAG ID.

· Use Hive queries to do data grouping or analysis. Airflow has HiveOperator to run hive queries and it should be used. User should use “hive_connection” and “hive_schema” provided in “config.yaml” in Airflow HiveOperator.

· The following project structure should be strictly adhered:

Project Root folder

o *.py - python file to define airflow dag and orchestration of various tasks

o config.yaml - this file will be supplied by SkillGrader platform and will contain dag_id, input_path, output_path, hive_connection and hive_schema parameters.

o java_task – this folder (optional) should contain tasks written using java program

§ pom.xml - Maven build file to compile java programs

§ src – folder containing Java programs

§ target – this folder will be created by Auto SkillGrader platform through Maven Build and jar file will be available at this folder. Use the Jar created inside this folder in your Airflow task through BashOperator

o python_task – this folder (optional) should contain tasks written in python

§ *.py - python file containing logic for the tasks. Use this python file in Airflow task through PythonOperator

o hive_task – this folder (mandatory) will contain tasks written using hive queries

§ *.hql - Hive query languages. Use this Hive query in Airflow task through HiveOperator

o shell_task – this folder (optional) should contain tasks written in Bash scripts

§ *.sh - shell scripts containing logic for the tasks. Use this file in Airflow task through BashOperator

· During code submission, remove all libraries/binaries and remove “target” folder from the Java_task folder and zip the entire project folder and submit the .zip file



